# Load Testing & Optimization Agent - Enhanced with Browser Testing

A professional-grade load testing system that combines k6 protocol-level testing with xk6-browser front-end performance analysis and AI-powered optimization recommendations. Test any web application and get comprehensive insights from both server and client perspectives.

## ğŸ“– Documentation

**[ğŸ“– Full Documentation](https://colespicer.github.io/load-opt-agent)** - Complete guides and reference  
**[ğŸš€ Quick Start Guide](https://colespicer.github.io/load-opt-agent/quick-start)** - Get up and running in minutes  
**[âš™ï¸ Configuration Reference](https://colespicer.github.io/load-opt-agent/configuration)** - YAML configuration options

## ğŸŒŸ New Features - Browser Testing Integration

### ğŸŒ xk6-browser Support
- **Real Browser Testing**: Uses actual Chromium browser for realistic front-end performance testing
- **Core Web Vitals**: Measures FCP, LCP, FID, CLS, and other user-centric metrics
- **User Interaction Simulation**: Clicks, scrolls, and interacts with page elements
- **Resource Loading Analysis**: Browser-level resource timing and optimization insights
- **Layout Shift Detection**: Identifies visual stability issues

### ğŸ”„ Dual Testing Modes
- **Protocol Testing**: Traditional k6 HTTP-level load testing (high concurrency)
- **Browser Testing**: xk6-browser front-end performance testing (lower concurrency, higher realism)
- **Combined Testing**: Run both tests for comprehensive analysis

## Features

### ğŸ³ Core Load Testing
- **Dockerized k6 Test Runner**: Containerized load testing for consistent environments
- **xk6-browser Integration**: Real browser testing with Chromium
- **YAML Configuration**: Simple, readable configuration files for test parameters
- **Comprehensive Metrics**: 21+ k6 metrics + Core Web Vitals + browser-specific metrics
- **Performance Thresholds**: Built-in performance validation with configurable thresholds
- **Multiple Test Scenarios**: Support for different application types and load patterns

### ğŸŒ Browser-Level Analysis
- **Core Web Vitals**: First Contentful Paint, Largest Contentful Paint, First Input Delay, Cumulative Layout Shift
- **Navigation Timing**: DOM Content Loaded, Load Complete, Time to Interactive
- **Resource Analysis**: Browser-level resource loading and optimization insights
- **User Interaction Metrics**: Script execution time, interaction responsiveness
- **Visual Stability**: Layout shift detection and analysis

### ğŸ¤– AI-Powered Analysis
- **OpenAI Integration**: GPT-4o-mini powered optimization recommendations
- **Technology Templates**: Technology-specific optimization patterns
- **Page Resource Analysis**: Identifies performance bottlenecks in page assets
- **Enhanced Metrics Analysis**: Deep dive into k6 performance data
- **Browser Performance Insights**: Front-end specific optimization recommendations
- **Actionable Recommendations**: Prioritized optimization suggestions

### ğŸ“Š Results Management
- **Organized Output**: Site-based organization with timestamped test runs
- **Latest Results**: Automatic symlinks to most recent test results
- **Navigation Tools**: Easy result browsing with `list_test_results.py`
- **Comprehensive Reports**: Multiple analysis outputs for complete insights
- **Historical Tracking**: Maintain test history for performance trends
- **Combined Analysis**: Protocol + browser results in unified reports

### ğŸ”§ Developer Experience
- **Professional Documentation**: Modern docs with Mintlify and GitHub Pages
- **Utility Scripts**: Comprehensive set of analysis and testing tools
- **Clean Architecture**: Well-organized, maintainable codebase
- **Extensible Design**: Easy to add new features and analysis tools

## Quick Start

### Prerequisites

- Docker
- Python 3.7+
- Required Python packages (install with `pip install -r requirements.txt`)

### Setup

1. **Install dependencies**:
```bash
pip install -r requirements.txt
```

2. **Configure environment** (for AI analysis):
```bash
cp env.example .env
# Add your OpenAI API key to .env
```

3. **Run a comprehensive load test**:
```bash
# Run both protocol and browser tests with AI analysis
python run_test.py configs/comprehensive_test.yaml

# Run technical analysis only (no AI, faster, no API costs)
python run_test.py configs/technical_analysis.yaml

# Run only protocol testing (traditional k6)
python run_test.py configs/pop_website_test.yaml

# Run only browser testing (front-end performance)
python run_test.py configs/browser_test.yaml
```

4. **Check results**:
```bash
# List all test results
python scripts/list_test_results.py list

# View latest results
python scripts/list_test_results.py latest

# View results for specific site
python scripts/list_test_results.py latest pop-website-2024-dev.azurewebsites.net
```

## Test Types

### ğŸ”Œ Protocol Testing (k6)
- **High concurrency**: 50+ virtual users
- **HTTP-level metrics**: Response times, error rates, throughput
- **Network analysis**: DNS, TLS, server processing times
- **Resource optimization**: Compression, caching analysis

### ğŸŒ Browser Testing (xk6-browser)
- **Real browser**: Chromium-based testing
- **Core Web Vitals**: User-centric performance metrics
- **Front-end analysis**: JavaScript execution, layout shifts
- **User interactions**: Click, scroll, form interactions

### ğŸ”„ Combined Testing
- **Best of both worlds**: Protocol + browser insights
- **Comprehensive analysis**: Server + client performance
- **Unified recommendations**: End-to-end optimization suggestions

### ğŸ”§ Technical Analysis (No AI)
- **Fast execution**: No OpenAI API calls
- **Cost effective**: No API costs
- **Raw data**: Technical metrics and insights
- **Debugging friendly**: Focus on technical components

## Configuration

### Basic Configuration

Edit `configs/test_config.yaml`:
```yaml
# Target URL to test (any web application)
target: https://example.com/contact

# Number of virtual users (concurrent users)
vus: 50

# Test duration (supports: 30s, 1m, 5m, 1h, etc.)
duration: 30s

# Test type: protocol, browser, or both
test_type: both

# Analysis settings
analysis_settings:
  run_page_resource_analysis: true
  run_enhanced_performance_analysis: true
  run_ai_analysis: true  # Set to false to skip AI analysis
  generate_readable_reports: true
  combine_results: true

# Site description for AI analysis (optional)
description: "Example website for load testing"

# Tags for categorization and AI analysis (optional)
tags:
  - "example"
  - "contact-form"
  - "static-site"
```

### Example Configurations

The project includes several example configurations:

- `configs/test_config.yaml` - Basic example
- `configs/pop_website_test.yaml` - POP website (protocol testing)
- `configs/browser_test.yaml` - Browser-based front-end testing
- `configs/comprehensive_test.yaml` - Both protocol and browser testing with AI
- `configs/technical_analysis.yaml` - Technical analysis only (no AI)
- `configs/wordpress_test.yaml` - WordPress site testing
- `configs/api_test.yaml` - API endpoint testing

### Analysis Settings

You can control which analysis components run:

```yaml
analysis_settings:
  run_page_resource_analysis: true      # Analyze page resources (images, scripts, etc.)
  run_enhanced_performance_analysis: true # Detailed k6/browser metrics analysis
  run_ai_analysis: true                 # AI-powered insights (requires OpenAI API)
  generate_readable_reports: true       # Generate HTML/Markdown reports
  combine_results: true                 # Combine protocol + browser results
```

**Benefits of disabling AI analysis:**
- **Faster execution**: No API calls to OpenAI
- **Cost savings**: No API usage costs
- **Technical focus**: Raw metrics and data
- **Debugging**: Easier to troubleshoot technical issues

## Test Metrics

### Protocol Metrics (k6)
- **Request Metrics**: Total requests, requests per second
- **Response Times**: Average, median, P95, P99 response times
- **Error Rates**: Failed request percentage
- **Payload Sizes**: Request and response sizes
- **Network Timing**: DNS, TLS, server processing, data transfer times

### Browser Metrics (xk6-browser)
- **Core Web Vitals**: FCP, LCP, FID, CLS
- **Navigation Timing**: DOM Content Loaded, Load Complete, Time to Interactive
- **Resource Loading**: Resource counts, sizes, loading times
- **User Interactions**: Script execution time, interaction responsiveness
- **Visual Stability**: Layout shift detection and analysis

### Performance Thresholds

Built-in performance thresholds (configurable):
- **Protocol**: 95% of requests should complete in < 2 seconds, Error rate < 10%
- **Browser**: FCP < 1.8s, LCP < 2.5s, FID < 100ms, CLS < 0.1

## Output Files

After running a test, the following files are generated:

### Protocol Testing
- `protocol_summary.json` - Raw k6 metrics in JSON format
- `test_report.json` - Formatted test summary with key metrics

### Browser Testing
- `browser_summary.json` - Raw xk6-browser metrics
- `browser_analysis_report.json` - Browser performance analysis

### Combined Testing
- `combined_test_report.json` - Unified protocol + browser results
- `ai_analysis_report.json` - AI-generated optimization recommendations
- `page_resource_analysis.json` - Page resource analysis results
- `enhanced_analysis_report.json` - Enhanced performance analysis

### Reports
- `ai_analysis_report.html` - Interactive HTML report
- `ai_analysis_report.md` - Markdown report
- `load_test.log` - Detailed execution logs

## Supported Applications

This system can test any web application:

- **Content Management Systems**: AEM, WordPress, Drupal
- **Single Page Applications**: React, Vue, Angular, Svelte
- **APIs**: REST APIs, GraphQL endpoints
- **Static Sites**: HTML, CSS, JavaScript sites
- **E-commerce**: Shopify, WooCommerce, custom solutions
- **Progressive Web Apps**: PWA performance and functionality

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   YAML Config   â”‚â”€â”€â”€â–¶â”‚  Python Runner  â”‚â”€â”€â”€â–¶â”‚  Docker + k6    â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ - target URL    â”‚    â”‚ - Config parse  â”‚    â”‚ - Protocol test â”‚
â”‚ - VUs           â”‚    â”‚ - Docker build  â”‚    â”‚ - 21+ metrics   â”‚
â”‚ - duration      â”‚    â”‚ - Test executionâ”‚    â”‚ - JSON export   â”‚
â”‚ - test_type     â”‚    â”‚ - Output org    â”‚    â”‚ - Performance   â”‚
â”‚ - description   â”‚    â”‚ - Site structureâ”‚    â”‚ - Thresholds    â”‚
â”‚ - tags          â”‚    â”‚ - Dual testing  â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  Docker + xk6   â”‚
                       â”‚    Browser      â”‚
                       â”‚                 â”‚
                       â”‚ - Browser test  â”‚
                       â”‚ - Core Web Vitalsâ”‚
                       â”‚ - User interactionsâ”‚
                       â”‚ - Chromium      â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  Analysis Layer â”‚
                       â”‚                 â”‚
                       â”‚ - Page Resourcesâ”‚
                       â”‚ - Enhanced k6   â”‚
                       â”‚ - Browser Metricsâ”‚
                       â”‚ - AI Analysis   â”‚
                       â”‚ - OpenAI GPT-4o â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚ Organized Outputâ”‚
                       â”‚                 â”‚
                       â”‚ output/         â”‚
                       â”‚ â”œâ”€â”€ site_name/  â”‚
                       â”‚ â”‚   â””â”€â”€ timestamp/â”‚
                       â”‚ â”‚       â”œâ”€â”€ protocol_summary.jsonâ”‚
                       â”‚ â”‚       â”œâ”€â”€ browser_summary.jsonâ”‚
                       â”‚ â”‚       â”œâ”€â”€ test_report.jsonâ”‚
                       â”‚ â”‚       â”œâ”€â”€ browser_analysis_report.jsonâ”‚
                       â”‚ â”‚       â”œâ”€â”€ combined_test_report.jsonâ”‚
                       â”‚ â”‚       â”œâ”€â”€ page_resource_analysis.jsonâ”‚
                       â”‚ â”‚       â”œâ”€â”€ enhanced_analysis_report.jsonâ”‚
                       â”‚ â”‚       â””â”€â”€ ai_analysis_report.jsonâ”‚
                       â”‚ â””â”€â”€ latest -> timestamp/â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Development

### Project Structure

```
load-opt-agent/
â”œâ”€â”€ ğŸ“– docs/                    # Documentation
â”œâ”€â”€ ğŸ“‹ configs/                # Load test configurations
â”‚   â”œâ”€â”€ test_config.yaml       # Basic test configuration
â”‚   â”œâ”€â”€ browser_test.yaml      # Browser-only test config
â”‚   â”œâ”€â”€ comprehensive_test.yaml # Both protocol and browser
â”‚   â”œâ”€â”€ wordpress_test.yaml    # WordPress test config
â”‚   â”œâ”€â”€ api_test.yaml          # API test config
â”‚   â””â”€â”€ pop_website_test.yaml  # POP website test config
â”œâ”€â”€ ğŸ”§ scripts/                # Utility and analysis scripts
â”‚   â”œâ”€â”€ browser_metrics_analyzer.py    # Browser metrics analysis
â”‚   â”œâ”€â”€ page_resource_analyzer.py      # Page resource analysis
â”‚   â”œâ”€â”€ enhanced_performance_analyzer.py # Enhanced k6 analysis
â”‚   â”œâ”€â”€ analyze_k6_metrics.py          # k6 metrics analysis
â”‚   â”œâ”€â”€ list_test_results.py           # Test results navigation
â”‚   â”œâ”€â”€ test_system.py                 # System testing
â”‚   â”œâ”€â”€ test_ai_analysis.py            # AI analysis testing
â”‚   â”œâ”€â”€ test_openai_integration.py     # OpenAI integration testing
â”‚   â”œâ”€â”€ parse_results.py               # Results parsing
â”‚   â”œâ”€â”€ show_ai_prompts.py             # AI prompt display
â”‚   â”œâ”€â”€ show_template_usage.py         # Template usage demo
â”‚   â””â”€â”€ README.md                      # Scripts documentation
â”œâ”€â”€ ğŸ¤– ai_analysis/            # AI analysis components
â”‚   â”œâ”€â”€ openai_enhanced_agent.py       # AI-enhanced analysis
â”‚   â””â”€â”€ technology_templates.yaml      # Technology-specific patterns
â”œâ”€â”€ ğŸ§ª tests/                  # k6 test scripts
â”‚   â”œâ”€â”€ load_test.js           # Protocol-level k6 test script
â”‚   â””â”€â”€ browser_load_test.js   # Browser-level xk6-browser test script
â”œâ”€â”€ ğŸ³ docker/                 # Docker configuration
â”‚   â”œâ”€â”€ Dockerfile             # k6 container definition
â”‚   â””â”€â”€ Dockerfile.browser     # xk6-browser container definition
â”œâ”€â”€ ğŸ“Š output/                 # Test results (auto-created)
â”‚   â””â”€â”€ [site_name]/           # Organized by site
â”‚       â””â”€â”€ [timestamp]/       # Organized by test run
â”‚           â”œâ”€â”€ protocol_summary.json   # Protocol test metrics
â”‚           â”œâ”€â”€ browser_summary.json    # Browser test metrics
â”‚           â”œâ”€â”€ test_report.json # Formatted results
â”‚           â”œâ”€â”€ browser_analysis_report.json # Browser analysis
â”‚           â”œâ”€â”€ combined_test_report.json # Combined results
â”‚           â”œâ”€â”€ page_resource_analysis.json # Page analysis
â”‚           â”œâ”€â”€ enhanced_analysis_report.json # Enhanced analysis
â”‚           â””â”€â”€ ai_analysis_report.json # AI recommendations
â”œâ”€â”€ ğŸ“„ run_test.py             # Main test runner
â”œâ”€â”€ ğŸ“‹ requirements.txt        # Python dependencies
â”œâ”€â”€ ğŸ”‘ env.example             # Environment variables template
â”œâ”€â”€ ğŸš« .gitignore             # Git ignore rules
â””â”€â”€ ğŸ“– README.md              # This file
```

### Extending the System

The system is designed for easy extension:

1. **New Test Types**: Add new k6 test scripts in `tests/`
2. **Browser Extensions**: Extend xk6-browser functionality in `tests/browser_load_test.js`
3. **Configuration Options**: Extend YAML schema in `run_test.py`
4. **Metrics**: Add custom k6 metrics in `tests/load_test.js`
5. **Analysis Scripts**: Add new analysis tools in `scripts/`
6. **AI Templates**: Extend technology patterns in `ai_analysis/technology_templates.yaml`
7. **Output Formats**: Extend reporting in `run_test.py`
8. **Documentation**: Add new guides in `docs/`

## Troubleshooting

### Common Issues

1. **Docker not running**: Ensure Docker daemon is started
2. **Permission errors**: Run with appropriate Docker permissions
3. **Network issues**: Check target URL accessibility
4. **Browser test failures**: Ensure sufficient system resources for Chromium
5. **Timeout errors**: Increase timeout in `run_test.py`

### Browser Testing Tips

- **Resource requirements**: Browser tests need more RAM and CPU
- **Lower concurrency**: Use fewer VUs for browser tests (3-5 vs 25-50)
- **Longer timeouts**: Browser tests take longer to complete
- **System resources**: Ensure adequate memory for Chromium instances

### Logs

Check `load_test.log` for detailed execution information and error messages.

## Next Steps (Future Phases)

This project includes Phase 1 (Dockerized Load Testing) and Phase 2 (AI-Powered Optimization). Future phases will include:

- **Phase 3**: Advanced test scenarios and workflows
- **Phase 4**: Real-time monitoring and alerting
- **Phase 5**: Integration with CI/CD pipelines
- **Phase 6**: Multi-site dashboard and reporting
- **Phase 7**: Advanced browser automation and visual regression testing

## License

This project is part of the POP Agents initiative for automated performance optimization.
